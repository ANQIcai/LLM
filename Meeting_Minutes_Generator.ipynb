{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNpdcBNlEu6VYoCZmfrGYa9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7uV3QqMG8NlF",
        "outputId": "2c3f9724-e738-4b9f-f67e-4aa96e556391"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 324, in run\n",
            "    session = self.get_default_session(options)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/index_command.py\", line 71, in get_default_session\n",
            "    self._session = self.enter_context(self._build_session(options))\n",
            "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/index_command.py\", line 100, in _build_session\n",
            "    session = PipSession(\n",
            "              ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/network/session.py\", line 344, in __init__\n",
            "    self.headers[\"User-Agent\"] = user_agent()\n",
            "                                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/network/session.py\", line 177, in user_agent\n",
            "    setuptools_dist = get_default_environment().get_distribution(\"setuptools\")\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 189, in get_distribution\n",
            "    return next(matches, None)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 184, in <genexpr>\n",
            "    matches = (\n",
            "              ^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/base.py\", line 612, in iter_all_distributions\n",
            "    for dist in self._iter_distributions():\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 177, in _iter_distributions\n",
            "    for dist in finder.find_eggs(location):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 144, in find_eggs\n",
            "    yield from self._find_eggs_in_dir(location)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_envs.py\", line 111, in _find_eggs_in_dir\n",
            "    from pip._vendor.pkg_resources import find_distributions\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3291, in <module>\n",
            "    @_call_aside\n",
            "     ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3266, in _call_aside\n",
            "    f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3304, in _initialize_master_working_set\n",
            "    working_set = WorkingSet._build_master()\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 591, in _build_master\n",
            "    ws = cls()\n",
            "         ^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 584, in __init__\n",
            "    self.add_entry(entry)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 640, in add_entry\n",
            "    for dist in find_distributions(entry, True):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2102, in find_on_path\n",
            "    yield from factory(fullpath)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2159, in distributions_from_metadata\n",
            "    if len(os.listdir(path)) == 0:\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1536, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1634, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1644, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1706, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 978, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.11/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1230, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1114, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1094, in flush\n",
            "    self.stream.flush()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TextStreamer\n",
        "from openai import OpenAI\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "from IPython.display import Markdown, display"
      ],
      "metadata": {
        "id": "lTowUonB751m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "DEEPSEEK = \"deepseek-ai/deepseek-coder-6.7b-base\"\n",
        "AUDIO_MODEL = \"whisper-1\""
      ],
      "metadata": {
        "id": "UgtpahjJ77Nn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_audio(audio_path, openai_api_key):\n",
        "    \"\"\"\n",
        "    Process audio file and generate meeting minutes\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Initialize OpenAI client\n",
        "        openai_client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "        # Transcribe audio\n",
        "        with open(audio_path, \"rb\") as audio_file:\n",
        "            transcription = openai_client.audio.transcriptions.create(\n",
        "                model=AUDIO_MODEL,\n",
        "                file=audio_file,\n",
        "                response_format=\"text\"\n",
        "            )\n",
        "\n",
        "        # Use OpenAI for generating minutes as well\n",
        "        system_message = \"You are an assistant that produces minutes of meetings from transcripts, with summary, key discussion points, takeaways and action items with owners, in markdown.\"\n",
        "        user_prompt = f\"Below is an extract transcript of a meeting. Please write minutes in markdown, including a summary with attendees, location and date; discussion points; takeaways; and action items with owners.\\n{transcription}\"\n",
        "\n",
        "        response = openai_client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_message},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        minutes = response.choices[0].message.content\n",
        "\n",
        "        return minutes, transcription\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\", \"Transcription failed\""
      ],
      "metadata": {
        "id": "fBcYLSd4790j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vmZ3qtel7qvd",
        "outputId": "37d6ff63-507d-486e-b608-1a24434ab786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://86bd3892db2d7551da.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://86bd3892db2d7551da.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
            "----\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://86bd3892db2d7551da.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://86bd3892db2d7551da.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def create_gradio_interface():\n",
        "    \"\"\"\n",
        "    Create and launch the Gradio interface\n",
        "    \"\"\"\n",
        "    # Define the interface\n",
        "    with gr.Blocks() as ui:\n",
        "        gr.Markdown(\"# Meeting Minutes Generator\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                audio_input = gr.Audio(\n",
        "                    label=\"Upload Audio File\",\n",
        "                    type=\"filepath\"\n",
        "                )\n",
        "                openai_key = gr.Textbox(\n",
        "                    label=\"OpenAI API Key\",\n",
        "                    type=\"password\"\n",
        "                )\n",
        "                process_btn = gr.Button(\"Generate Minutes\")\n",
        "\n",
        "            with gr.Column():\n",
        "                minutes_output = gr.Markdown(\n",
        "                    label=\"Meeting Minutes\"\n",
        "                )\n",
        "                transcription_output = gr.Textbox(\n",
        "                    label=\"Transcription\",\n",
        "                    lines=10\n",
        "\n",
        "        # Connect the interface\n",
        "        process_btn.click(\n",
        "            fn=process_audio,\n",
        "            inputs=[audio_input, openai_key],\n",
        "            outputs=[minutes_output, transcription_output]\n",
        "        )\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        ## Instructions\n",
        "        1. Upload an audio file of your meeting\n",
        "        2. Enter your OpenAI API key\n",
        "        3. Click 'Generate Minutes' to process the audio\n",
        "\n",
        "        Note: This tool has no access to your OPENAI API KEY. This tool uses OpenAI's Whisper for transcription and GPT-3.5 for minutes generation.\n",
        "        \"\"\")\n",
        "\n",
        "    # Launch the interface\n",
        "    ui.launch(share=True)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_gradio_interface()"
      ]
    }
  ]
}